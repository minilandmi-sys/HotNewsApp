import streamlit as st
import feedparser
import pandas as pd
from datetime import datetime
import time
from io import BytesIO
import requests # æ–°å¢ï¼šç”¨æ–¼å‘¼å« Gemini API
from PIL import Image, ImageDraw, ImageFont 

# ================= LLM API è¨­å®š (å·²è½‰æ›ç‚º Gemini) =================
GEMINI_MODEL = "gemini-2.5-flash" # å·²æ›´æ–°ç‚ºæ­£å¼ç‰ˆæœ¬
GEMINI_API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent"

# å˜—è©¦è®€å– GEMINI API é‡‘é‘°
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
    st.error("âš ï¸ éŒ¯èª¤ï¼šè«‹åœ¨ Streamlit Secrets ä¸­è¨­å®š **GEMINI_API_KEY**ï¼")
    API_KEY = ""

# 4 å€‹ç¶²ç«™çš„ RSS
RSS_FEEDS = {
    "å¦æ–°è": "https://www.niusnews.com/feed",
    "Women's Health TW": "https://www.womenshealthmag.com/tw/rss/all.xml",
    "BEAUTYç¾äººåœˆ": "https://www.beauty321.com/feed_pin",
    "A Day Magazine": "https://www.adaymag.com/feed"
}

# ================= è¼”åŠ©å‡½å¼ (åŸæœ‰çš„ RSS è™•ç†) =================

def parse_entries(entries):
    parsed_list = []
    for entry in entries:
        published_time = None
        if hasattr(entry, "published_parsed") and entry.published_parsed:
            published_time = datetime(*entry.published_parsed[:6])
        elif hasattr(entry, "updated_parsed") and entry.updated_parsed:
            published_time = datetime(*entry.updated_parsed[:6])
        if not published_time:
            published_time = datetime.now()

        parsed_list.append({
            "æ¨™é¡Œ": entry.title if "title" in entry else "(ç„¡æ¨™é¡Œ)",
            "é€£çµ": entry.link if "link" in entry else "",
            "ç™¼ä½ˆæ™‚é–“": published_time.strftime("%Y-%m-%d %H:%M"),
            "ä¾†æº": ""
        })
    return parsed_list

def fetch_top5_each_site():
    all_entries = []
    for site, url in RSS_FEEDS.items():
        feed = feedparser.parse(url)
        if not feed.entries:
            continue

        entries = parse_entries(feed.entries)
        entries_sorted = entries[:5]
        for item in entries_sorted:
            item["ä¾†æº"] = site
        all_entries.extend(entries_sorted)

        time.sleep(1)

    all_entries.sort(key=lambda x: x["ç™¼ä½ˆæ™‚é–“"], reverse=True)
    return pd.DataFrame(all_entries)

# ================= æ¨¡çµ„ 2 & 3ï¼šè¦–è¦ºå…§å®¹ç”Ÿæˆ (Pillow å¯¦ç¾) =================

def get_font(size, bold=False):
    """å˜—è©¦è¼‰å…¥å¸¸è¦‹å­—é«”ï¼Œè‹¥å¤±æ•—å‰‡å›å‚³é è¨­å­—é«”"""
    try:
        # æ¨¡æ“¬ Impact æˆ– Arial Bold ä½œç‚ºæ¢—åœ–å­—é«”
        # Note: åœ¨å¯¦éš›éƒ¨ç½²ç’°å¢ƒä¸­ï¼Œæ‚¨å¯èƒ½éœ€è¦æä¾› 'Impact.ttf' æˆ– CJK å­—é«”æª”æ¡ˆ
        font_name = "arial.ttf" if not bold else "arialbd.ttf"
        return ImageFont.truetype(font_name, size)
    except IOError:
        # è‹¥æ‰¾ä¸åˆ°ç‰¹å®šå­—é«”ï¼Œä½¿ç”¨é è¨­å­—é«”
        return ImageFont.load_default()

def generate_visual_content(title, meme_text, ratio='1:1', uploaded_file=None): # æ–°å¢ uploaded_file åƒæ•¸
    """
    ä½¿ç”¨ Pillow å‡½å¼åº«ï¼Œåœ¨ä¼ºæœå™¨ç«¯ç”Ÿæˆå¸¶æœ‰æ¢—åœ–æ–‡å­—çš„åœ–ç‰‡ã€‚
    """
    # å®šç¾©å°ºå¯¸
    WIDTH = 1000
    HEIGHT = 1778 if ratio == '9:16' else 1000
    
    if uploaded_file is not None:
        # è¼‰å…¥ä¸Šå‚³çš„åœ–ç‰‡ä¸¦ç¸®æ”¾è‡³æ¨¡æ¿å°ºå¯¸
        try:
            img = Image.open(uploaded_file).convert("RGB")
            # ä½¿ç”¨ LANCZOS æ¼”ç®—æ³•é€²è¡Œé«˜å“è³ªç¸®æ”¾
            img = img.resize((WIDTH, HEIGHT), Image.Resampling.LANCZOS)
        except Exception as e:
            # åœ–ç‰‡è¼‰å…¥å¤±æ•—ï¼Œä½¿ç”¨è—è‰²é è¨­æ¨¡æ¿ä½œç‚ºå‚™æ´
            st.warning(f"âš ï¸ åœ–ç‰‡è¼‰å…¥å¤±æ•—ï¼Œä½¿ç”¨è—è‰²é è¨­æ¨¡æ¿ã€‚éŒ¯èª¤: {e}")
            img = Image.new('RGB', (WIDTH, HEIGHT), color='#1e3a8a')
    else:
        # å»ºç«‹åŸºç¤åœ–ç‰‡ (è—è‰²èƒŒæ™¯ä½œç‚ºæ¨¡æ¿)
        img = Image.new('RGB', (WIDTH, HEIGHT), color='#1e3a8a')

    draw = ImageDraw.Draw(img)

    # --- ç¹ªè£½æ¨¡æ¿æ¨™é¡Œèˆ‡æ–‡ç« æ¨™é¡Œ ---
    title_size = int(WIDTH / 35)
    article_size = int(WIDTH / 50)
    
    title_font = get_font(title_size, bold=True)
    article_font = get_font(article_size, bold=False)

    # æ¨¡æ¿æ¨™é¡Œ (ä¿æŒå–®è¡Œç½®ä¸­)
    draw.text((WIDTH / 2, HEIGHT * 0.08), 
              "ã€ç¤¾ç¾¤å…§å®¹åŠ é€Ÿå™¨ã€‘è¦–è¦ºæ¨¡æ¿", 
              fill="#ffffff", 
              font=title_font, 
              anchor="mm")
    
    # æ–‡ç« æ¨™é¡Œ - å¯¦ç¾å¤šè¡Œè‡ªå‹•æ›è¡Œ (ä½¿ç”¨ç°¡æ˜“å­—å…ƒé™åˆ¶)
    article_to_display = title or "è«‹è¼¸å…¥æ–‡ç« æ¨™é¡Œä»¥è·Ÿé¢¨ç†±é»..."
    
    # é‡å°ä¸­æ–‡æ¨™é¡Œï¼Œæ¯è¡Œé™åˆ¶å¤§ç´„ 30 å€‹å­—å…ƒ (ç²—ç•¥ä¼°è¨ˆ 80% å¯¬åº¦)
    CHAR_LIMIT = 30 
    lines = []
    current_line = ""
    
    # è™•ç†æ¨™é¡Œæ›è¡Œ
    for char in article_to_display:
        # é€™è£¡ä½¿ç”¨ len() æ¨¡æ“¬å­—å…ƒæ•¸é™åˆ¶ï¼Œè€Œéç²¾æº–çš„åƒç´ è¨ˆç®—
        if len(current_line) < CHAR_LIMIT:
            current_line += char
        else:
            lines.append(current_line)
            current_line = char
    lines.append(current_line) # Add the last line

    lines = [line.strip() for line in lines if line.strip()] # æ¸…ç†ç©ºç™½è¡Œ

    y_start = HEIGHT * 0.15 # æ›è¡Œæ–‡å­—èµ·å§‹ Y åº§æ¨™
    line_height = article_size * 1.5 # è¡Œè·

    # ç¹ªè£½ wrapped æ–‡ç« æ¨™é¡Œ
    for i, line in enumerate(lines):
        draw.text((WIDTH / 2, y_start + i * line_height), 
                  line, 
                  fill="#ffffff", 
                  font=article_font, 
                  anchor="mt") # ä½¿ç”¨ 'mt' éŒ¨é»é€²è¡Œé ‚éƒ¨ç½®ä¸­å°é½Š

    # --- ç¹ªè£½æ¢—åœ–æ–‡å­— (ç™½å­—é»‘é‚Šæ•ˆæœ) ---
    if meme_text:
        meme_size = int(WIDTH / 12)
        y_pos = HEIGHT * 0.85
        meme_font = get_font(meme_size, bold=True)
        
        # æ¨¡æ“¬é»‘é‚Šæ•ˆæœ
        outline_width = 3 
        outline_color = "black"
        
        # ç¹ªè£½é»‘é‚Š
        for x_offset in range(-outline_width, outline_width + 1):
            for y_offset in range(-outline_width, outline_width + 1):
                if x_offset != 0 or y_offset != 0:
                    draw.text((WIDTH / 2 + x_offset, y_pos + y_offset), 
                              meme_text.upper(), 
                              font=meme_font, 
                              fill=outline_color, 
                              anchor="ms")
        
        # ç¹ªè£½ç™½è‰²ä¸»é«”
        draw.text((WIDTH / 2, y_pos), 
                  meme_text.upper(), 
                  font=meme_font, 
                  fill="white", 
                  anchor="ms")

    return img

# ================= æ¨¡çµ„ 3ï¼šAI æ–‡æ¡ˆå„ªåŒ–é‚è¼¯ (ä½¿ç”¨ Gemini API) =================

def generate_ai_copy(article_title, meme_text):
    """
    ä½¿ç”¨ Gemini API ç”Ÿæˆ 3 ä»½é‡å°ç¤¾ç¾¤è²¼æ–‡å„ªåŒ–çš„æ¨™é¡Œã€‚
    NOTE: è‹¥å‡ºç¾ 400 éŒ¯èª¤ï¼Œè«‹æª¢æŸ¥æ‚¨çš„ GEMINI_API_KEY æ˜¯å¦æœ‰æ•ˆä¸”å…·æœ‰è¶³å¤ æ¬Šé™ã€‚
    """
    if not API_KEY:
        return "API é‡‘é‘°æœªè¨­å®šï¼Œç„¡æ³•å‘¼å« Gemini APIã€‚"
        
    if not article_title or not meme_text:
        return None

    # ç³»çµ±æŒ‡ä»¤ï¼šè¨­å®šç‚ºæ©Ÿæ™ºçš„å°ç£ç¤¾ç¾¤ç·¨è¼¯ (å·²ä¿®æ”¹ç‚ºç”Ÿæˆæ¨™é¡Œ)
    system_prompt = "Act as a witty Taiwanese social media editor (ç¤¾ç¾¤å°ç·¨). Your output must be in Traditional Chinese. Based on the article title and the visual meme text provided by the user, generate 3 different, highly engaging, and clickable article titles/headlines ( suitable for a blog or social media post). Each title should be concise and separated by a single line break. Format your response using Markdown bullet points (*), NOT numbered lists."
            
    user_query = f"è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šç”Ÿæˆ 3 ä»½å„ªåŒ–çš„ç¤¾ç¾¤æ¨™é¡Œ:\n\næ–‡ç« æ¨™é¡Œ (æ ¸å¿ƒè³‡è¨Š): {article_title}\nè¦–è¦ºæ–‡æ¡ˆ (æ¢—åœ–æ–‡å­—): {meme_text}"

    headers = {
        "Content-Type": "application/json",
    }
    
    # æ§‹å»º Gemini API çš„ Payload
    payload = {
        "contents": [{"parts": [{"text": user_query}]}],
        "systemInstruction": {"parts": [{"text": system_prompt}]},
        "config": {
            "maxOutputTokens": 500,
            "temperature": 0.7
        }
    }

    try:
        # ç™¼èµ· API å‘¼å«
        response = requests.post(
            f"{GEMINI_API_URL}?key={API_KEY}", 
            headers=headers, 
            json=payload
        )
        response.raise_for_status() # å° HTTP éŒ¯èª¤ç¢¼æ‹‹å‡ºç•°å¸¸

        result = response.json()
        
        # æª¢æŸ¥ä¸¦æå–ç”Ÿæˆçš„æ–‡æœ¬
        if result and 'candidates' in result and len(result['candidates']) > 0 and 'parts' in result['candidates'][0]['content']:
            text = result['candidates'][0]['content']['parts'][0]['text']
            return text.strip()
        else:
            st.error("âš ï¸ Gemini API å›å‚³æ ¼å¼éŒ¯èª¤æˆ–ç„¡å…§å®¹ã€‚")
            return "API å›æ‡‰è§£æå¤±æ•—ã€‚"

    except requests.exceptions.RequestException as e:
        # ç”±æ–¼ 400 éŒ¯èª¤å¸¸èˆ‡é‡‘é‘°/æ¬Šé™ç›¸é—œï¼Œæ­¤è™•ä¿ç•™éŒ¯èª¤é¡¯ç¤ºä»¥åˆ©ä½¿ç”¨è€…æ’æŸ¥
        st.error(f"âš ï¸ Gemini API å‘¼å«å¤±æ•—: {e}")
        st.write(f"API å›æ‡‰ç‹€æ…‹ç¢¼: {response.status_code if 'response' in locals() else 'N/A'}")
        return "API å‘¼å«å¤±æ•—ã€‚"
    except Exception as e:
        st.error(f"âš ï¸ ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ï¼š{e}")
        return "æœªçŸ¥éŒ¯èª¤ã€‚"


# ================= Streamlit UI (ä¸»ç¨‹å¼) =================

st.title("ğŸ“° ç†±é–€æ–°èå ±è¡¨å·¥å…· (RSS)")

# å ±è¡¨ç”¢ç”Ÿå€ (ç¶­æŒåŸæœ‰é‚è¼¯)
if st.button("ğŸ“Š ç”¢ç”Ÿæœ€æ–°å ±è¡¨"):
    df = fetch_top5_each_site()
    st.session_state.df = df # å°‡ DataFrame å­˜å…¥ session_state
    
    if df.empty:
        st.warning("âš ï¸ æ²’æœ‰æŠ“åˆ°ä»»ä½•æ–‡ç« ã€‚")
    else:
        st.success("âœ… å ±è¡¨å·²ç”¢ç”Ÿï¼")
        st.dataframe(df)

        # è½‰æ›ç‚º Excel ä¸¦ä¸‹è¼‰
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False)
        excel_data = output.getvalue()

        today = datetime.now().strftime("%Y-%m-%d")
        filename = f"{today}_HotNews.xlsx"

        st.download_button(
            label="â¬‡ï¸ ä¸‹è¼‰ Excel å ±è¡¨",
            data=excel_data,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
else:
    # ç¢ºä¿ session_state.df åœ¨ç¬¬ä¸€æ¬¡åŸ·è¡Œæ™‚å­˜åœ¨
    if 'df' not in st.session_state:
        st.session_state.df = pd.DataFrame()


# ================= ç¤¾ç¾¤å…§å®¹åŠ é€Ÿå™¨ (æ–°å¢æ¨¡çµ„) =================
st.markdown("---")
st.header("ğŸš€ ç¤¾ç¾¤å…§å®¹åŠ é€Ÿå™¨")
st.markdown("ä½¿ç”¨ç†±é»æ–‡ç« æ¨™é¡Œï¼Œå¿«é€Ÿè£½ä½œæ¢—åœ–è¦–è¦ºèˆ‡å„ªåŒ–æ¨™é¡Œï¼") # ä¿®æ­£æ–‡æ¡ˆç‚ºæ¨™é¡Œ

# --- æ¨¡çµ„ 1: æ–‡ç« è¼¸å…¥èˆ‡æ¯”ä¾‹é¸æ“‡ ---
# å°‡ä¸Šå‚³åœ–ç‰‡åŠŸèƒ½èˆ‡æ¯”ä¾‹é¸æ“‡æ”¾åœ¨åŒä¸€æ¬„
with st.container():
    col1, col2 = st.columns([2, 1])

    with col1:
        # æ¨¡çµ„ 1: æ–‡ç« æ¨™é¡Œè¼¸å…¥ (å¾å ±è¡¨é¸æ“‡æˆ–æ‰‹å‹•è¼¸å…¥)
        if not st.session_state.df.empty:
            titles = ["--- æ‰‹å‹•è¼¸å…¥ ---"] + st.session_state.df["æ¨™é¡Œ"].tolist()
            selected_title_option = st.selectbox(
                "é¸æ“‡æˆ–è¼¸å…¥ç†±é»æ–‡ç« æ¨™é¡Œï¼š", 
                titles, 
                key="title_select"
            )
            
            if selected_title_option == "--- æ‰‹å‹•è¼¸å…¥ ---":
                article_title = st.text_input("æˆ–æ‰‹å‹•è¼¸å…¥æ–‡ç« æ¨™é¡Œ:", value="", key="title_manual")
            else:
                article_title = selected_title_option
        else:
            article_title = st.text_input("æ‰‹å‹•è¼¸å…¥æ–‡ç« æ¨™é¡Œ (è«‹å…ˆç”¢ç”Ÿå ±è¡¨):", value="", key="title_manual_only")
        
        # æ¨¡çµ„ 3: è¦–è¦ºåŒ–æ–‡æ¡ˆè¼¸å…¥
        meme_text = st.text_area("è¦–è¦ºåŒ–æ–‡æ¡ˆ (æ¢—åœ–æ–‡å­—):", 
                                  value="", 
                                  height=100,
                                  placeholder="è¼¸å…¥è¦ç–ŠåŠ åœ¨åœ–ç‰‡ä¸Šçš„æ¨™èªæˆ–æ¢—åœ–æ–‡å­—ï¼Œä¾‹å¦‚ï¼šå¥½éšªæœ‰è·Ÿåˆ°é€™æ³¢ç†±é»ï¼")
    
    with col2:
        # æ¨¡çµ„ 2: æ¯”ä¾‹é¸æ“‡
        st.markdown("##### è²¼æ–‡æ¯”ä¾‹é¸æ“‡")
        ratio = st.radio(
            "é¸æ“‡åœ–ç‰‡æ¯”ä¾‹ï¼š",
            ('1:1', '9:16'),
            key='ratio_select',
            horizontal=True
        )
        
        # æ–°å¢åœ–ç‰‡ä¸Šå‚³åŠŸèƒ½
        uploaded_file = st.file_uploader("ğŸ–¼ï¸ ä¸Šå‚³èƒŒæ™¯åœ–ç‰‡ (å¯é¸)", type=["jpg", "jpeg", "png"])

# --- æ¨¡çµ„ 2: è¦–è¦ºæ¨¡æ¿é è¦½ ---
st.markdown("#### ğŸ–¼ï¸ è¦–è¦ºæ¨¡æ¿é è¦½")
# å‘¼å«å‡½å¼æ™‚å‚³å…¥ä¸Šå‚³çš„æª”æ¡ˆ
visual_img = generate_visual_content(article_title, meme_text, ratio, uploaded_file)
st.image(visual_img, caption="è¦–è¦ºå…§å®¹é è¦½ (ç”± Pillow æ¨¡æ“¬ Canvas ç¹ªè£½ï¼Œå·²æ”¯æ´é•·æ¨™é¡Œæ›è¡Œèˆ‡è‡ªè¨‚èƒŒæ™¯)", use_column_width='auto')

# --- ä¸‹è¼‰æŒ‰éˆ• (åªç•™ JPG) ---
# åªä¿ç•™ JPG ä¸‹è¼‰æŒ‰éˆ•
img_byte_arr_jpg = BytesIO()
visual_img.save(img_byte_arr_jpg, format='JPEG', quality=95) # quality=95 ä»¥ç¢ºä¿è¼ƒé«˜å“è³ªçš„ JPG

st.download_button(
    label="â¬‡ï¸ ä¸‹è¼‰æˆå“ (JPG)",
    data=img_byte_arr_jpg.getvalue(),
    file_name=f"{article_title[:10].replace('/', '_')}_meme.jpg",
    mime="image/jpeg"
)

# --- æ¨¡çµ„ 3: AI æ–‡æ¡ˆå„ªåŒ– ---
st.markdown("---")
st.subheader("ğŸ¤– AI ç¤¾ç¾¤æ¨™é¡Œå„ªåŒ– (ç”Ÿæˆ 3 ä»½æ¨™é¡Œ)") # ä¿®æ­£æ–‡æ¡ˆç‚ºæ¨™é¡Œ

if st.button("âœ¨ ç”Ÿæˆå„ªåŒ–ç¤¾ç¾¤æ¨™é¡Œ", key="generate_new_copy_btn"): # ä¿®æ­£æ–‡æ¡ˆç‚ºæ¨™é¡Œ
    if not article_title or not meme_text:
        st.error("âš ï¸ è«‹ç¢ºèªå·²è¼¸å…¥**æ–‡ç« æ¨™é¡Œ**å’Œ**æ¢—åœ–æ–‡å­—**ã€‚")
    else:
        with st.spinner("AI æ­£åœ¨æ ¹æ“šæ‚¨çš„è¼¸å…¥æ’°å¯« 3 ä»½å„ªåŒ–æ¨™é¡Œä¸­..."): # ä¿®æ­£æ–‡æ¡ˆç‚ºæ¨™é¡Œ
            try:
                ai_text = generate_ai_copy(article_title, meme_text)
                if ai_text:
                    st.session_state.accelerator_copy = ai_text # å„²å­˜æ–°æ¨™é¡Œ
            except Exception as e:
                # éŒ¯èª¤è™•ç†å·²åœ¨ generate_ai_copy å…§éƒ¨å®Œæˆ
                pass

# é¡¯ç¤º AI ç”Ÿæˆçµæœ
if 'accelerator_copy' in st.session_state and st.session_state.accelerator_copy:
    st.success("âœ… 3 ä»½å„ªåŒ–æ¨™é¡Œç”Ÿæˆå®Œæˆï¼") # ä¿®æ­£æ–‡æ¡ˆç‚ºæ¨™é¡Œ
    # å°‡ Markdown æ ¼å¼çš„çµæœ (å¦‚ *) æ¸²æŸ“å‡ºä¾†
    st.markdown(st.session_state.accelerator_copy)
