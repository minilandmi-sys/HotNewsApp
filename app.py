import streamlit as st
import feedparser
import pandas as pd
from datetime import datetime
import time
from io import BytesIO
import google.generativeai as genai  # âœ… æ”¹ç”¨ Gemini

# ===================== è¨­å®š Gemini é‡‘é‘° =====================
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

# ===================== RSS è¨­å®š =====================
RSS_FEEDS = {
    "å¦æ–°è": "https://www.niusnews.com/feed",
    "Women's Health TW": "https://www.womenshealthmag.com/tw/rss/all.xml",
    "BEAUTYç¾äººåœˆ": "https://www.beauty321.com/feed_pin",
    "A Day Magazine": "https://www.adaymag.com/feed"
}

def parse_entries(entries):
    parsed_list = []
    for entry in entries:
        published_time = None
        if hasattr(entry, "published_parsed") and entry.published_parsed:
            published_time = datetime(*entry.published_parsed[:6])
        elif hasattr(entry, "updated_parsed") and entry.updated_parsed:
            published_time = datetime(*entry.updated_parsed[:6])
        if not published_time:
            published_time = datetime.now()

        parsed_list.append({
            "æ¨™é¡Œ": entry.title if "title" in entry else "(ç„¡æ¨™é¡Œ)",
            "é€£çµ": entry.link if "link" in entry else "",
            "ç™¼ä½ˆæ™‚é–“": published_time.strftime("%Y-%m-%d %H:%M"),
            "ä¾†æº": ""
        })
    return parsed_list

def fetch_top5_each_site():
    all_entries = []
    for site, url in RSS_FEEDS.items():
        feed = feedparser.parse(url)
        if not feed.entries:
            continue

        entries = parse_entries(feed.entries)
        entries_sorted = entries[:5]
        for item in entries_sorted:
            item["ä¾†æº"] = site
        all_entries.extend(entries_sorted)

        time.sleep(1)

    all_entries.sort(key=lambda x: x["ç™¼ä½ˆæ™‚é–“"], reverse=True)
    return pd.DataFrame(all_entries)

# ===================== Streamlit ä»‹é¢ =====================
st.title("ğŸ“° ç†±é–€æ–°èå ±è¡¨å·¥å…· (Gemini å…è²»ç‰ˆ)")

if st.button("ğŸ“Š ç”¢ç”Ÿæœ€æ–°å ±è¡¨"):
    df = fetch_top5_each_site()
    if df.empty:
        st.warning("âš ï¸ æ²’æœ‰æŠ“åˆ°ä»»ä½•æ–‡ç« ã€‚")
    else:
        st.success("âœ… å ±è¡¨å·²ç”¢ç”Ÿï¼")
        st.dataframe(df)

        # è½‰æˆ Excel ä¸¦ä¸‹è¼‰
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False)
        excel_data = output.getvalue()

        today = datetime.now().strftime("%Y-%m-%d")
        filename = f"{today}_HotNews.xlsx"

        st.download_button(
            label="â¬‡ï¸ ä¸‹è¼‰ Excel å ±è¡¨",
            data=excel_data,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

# ===================== è‡ªå‹•ç”Ÿæˆç¤¾ç¾¤æ–‡æ¡ˆ =====================
st.markdown("---")
st.subheader("âœï¸ è‡ªå‹•ç”Ÿæˆç¤¾ç¾¤æ–‡æ¡ˆè‰ç¨¿ (ç”± Gemini æä¾›)")

if 'df' not in st.session_state:
    st.session_state.df = pd.DataFrame()

if 'df' in locals() and not df.empty:
    st.session_state.df = df

if not st.session_state.df.empty:
    selected_title = st.selectbox("é¸æ“‡ä¸€ç¯‡æ–‡ç« ç”¢ç”Ÿæ–‡æ¡ˆï¼š", st.session_state.df["æ¨™é¡Œ"])
    if st.button("âœ¨ ç”Ÿæˆç¤¾ç¾¤æ–‡æ¡ˆ"):
        with st.spinner("Gemini æ­£åœ¨æ’°å¯«æ–‡æ¡ˆä¸­..."):
            try:
                model = genai.GenerativeModel("gemini-1.5-flash")  # âš¡ å…è²»é«˜é€Ÿç‰ˆæœ¬
                prompt = f"è«‹å¹«æˆ‘ç‚ºä»¥ä¸‹æ–‡ç« æ¨™é¡Œæ’°å¯«ä¸€æ®µ Facebook è²¼æ–‡æ–‡æ¡ˆï¼Œèªæ°£è‡ªç„¶ã€æœ‰è¶£ã€å£èªåŒ–ä¸¦åŠ å…¥ emojiï¼š\n\næ¨™é¡Œï¼š{selected_title}"
                response = model.generate_content(prompt)
                st.session_state.generated_text = response.text.strip()
            except Exception as e:
                st.error(f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

if 'generated_text' in st.session_state:
    st.success("âœ… æ–‡æ¡ˆç”Ÿæˆå®Œæˆï¼")
    st.write(st.session_state.generated_text)
else:
    st.info("è«‹å…ˆç”¢ç”Ÿå ±è¡¨ï¼Œå†ä½¿ç”¨æ–‡æ¡ˆç”ŸæˆåŠŸèƒ½ã€‚")
